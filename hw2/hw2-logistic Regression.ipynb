{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression implement stochastic gradient descent, Accury = 0.6875\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import pandas as pd\n",
    "import math\n",
    "from numpy import *\n",
    "#read data from file and convert it into right format\n",
    "dataframe = pd.read_csv(\"/Users/xing/Desktop/test/balloons.csv\", header=None)\n",
    "dataset = dataframe.values \n",
    "Col=len(dataset[0])-1\n",
    "X = dataset[:, 0:Col].astype(float)\n",
    "y = dataset[:, Col]\n",
    "\n",
    "#X,y=make_moons(n_samples=1000,noise=0.3,random_state=0)\n",
    "Col=len(X[0])\n",
    "h = .02  # step size in the mes\n",
    "def sigmoid(X):\n",
    "    return 1 / (1 + np.exp(-X))\n",
    "\n",
    "# using stochastic gradient descent do optimize, max_iter 500 pass, return the min value\n",
    "alpa=0.001\n",
    "max_iter=500\n",
    "weight=ones((Col,1))\n",
    "loss=zeros((len(X),1))\n",
    "def Gradient_descent(X,y,alpa,weight,max_iter):\n",
    "    for i in range(1,max_iter):\n",
    "        h=sigmoid((X.T*weight))\n",
    "        #for j in range(len(X)):\n",
    "        #    thea=0\n",
    "        #    for k in range(len(X[0])):\n",
    "        #        thea+=h[j][k]\n",
    "            #loss[j]=y[j]-thea\n",
    "        loss=y-h\n",
    "        weight=weight+alpa*(X.transpose())*loss\n",
    "\n",
    "Gradient_descent(X,y,alpa,weight,max_iter)\n",
    "\n",
    "def Accurylogregres(weights, test_x, test_y):\n",
    "    numSamples, numFeatures = shape(test_x)\n",
    "    matchCount = 0\n",
    "    for i in range(numSamples):\n",
    "        predict = sigmoid(test_x[i, :] * weights)[0, 0] > 0.5\n",
    "        if predict == bool(test_y[i]):\n",
    "            matchCount += 1\n",
    "    accuracy = float(matchCount) / numSamples\n",
    "    return accuracy\n",
    "\n",
    "print  \"logistic regression implement stochastic gradient descent, Accury =\" ,Accurylogregres(weight,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
